{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcalvachi/Metaanalysiscages/blob/master/Assignment1Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUuP6ZAbYuh-"
      },
      "source": [
        "# Assignment 1: Backpropagation and Multilayer Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrYwPCdqZiLV"
      },
      "source": [
        "Your Name: \n",
        "\n",
        "Name of the Students You Worked With:\n",
        "\n",
        "References You Consulted:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B3KIIQtZZNF"
      },
      "source": [
        "Feel free to use the Google Colab environment (https://colab.research.google.com/notebooks/welcome.ipynb) or follow the instructions on the course website (https://hms-dbmi.github.io/BMI_707/resources/) to setup python environment.\n",
        "\n",
        "## Part 1: Data Exploration (20 points)\n",
        "In this assignment, we will use a modified dataset from the Pima Indian Diabetes Database (https://www.kaggle.com/uciml/pima-indians-diabetes-database). This dataset is released under the CC0 1.0 Universal (CC0 1.0) Public Domain Dedication (https://creativecommons.org/publicdomain/zero/1.0/).\n",
        "\n",
        "Below is a brief data description of this dataset from Kaggle (https://www.kaggle.com/uciml/pima-indians-diabetes-database):\n",
        "\"This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\" \"The dataset consists of several medical predictor variables and one target variable, Outcome. Predictor variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\"\n",
        "\n",
        "**Please note that we have modified the dataset a little to simplify the analyses. Please use the codes below to read in the modified files.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VSpYmQTMkJ4"
      },
      "source": [
        "# import python packages\n",
        "import numpy as np              # linear algebra\n",
        "import pandas as pd             # to process the input files\n",
        "\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaTLmw6fNfi-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3895914c-85af-4775-c014-a97ca73f5594"
      },
      "source": [
        "# read in the data files; please use these files, instead of the raw files from the Pima Indian Diabetes Database\n",
        "train_data = pd.read_csv('https://www.dropbox.com/s/n0jjos6faoyqncp/diabetesTrain.csv?dl=1')\n",
        "test_data = pd.read_csv('https://www.dropbox.com/s/6uu2754iqv4cxei/diabetesTest.csv?dl=1')\n",
        "\n",
        "# check the data files\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>99.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>20.4</td>\n",
              "      <td>0.235</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>136.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.647</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>97.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>153.777049</td>\n",
              "      <td>18.2</td>\n",
              "      <td>0.147</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>90.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>28.962963</td>\n",
              "      <td>153.777049</td>\n",
              "      <td>23.5</td>\n",
              "      <td>0.191</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>188.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>28.962963</td>\n",
              "      <td>153.777049</td>\n",
              "      <td>47.9</td>\n",
              "      <td>0.137</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness     Insulin   BMI  \\\n",
              "0            2     99.0           70.0      16.000000   44.000000  20.4   \n",
              "1            7    136.0           74.0      26.000000  135.000000  26.0   \n",
              "2            1     97.0           70.0      15.000000  153.777049  18.2   \n",
              "3            2     90.0           60.0      28.962963  153.777049  23.5   \n",
              "4            8    188.0           78.0      28.962963  153.777049  47.9   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.235   27        0  \n",
              "1                     0.647   51        0  \n",
              "2                     0.147   21        0  \n",
              "3                     0.191   25        0  \n",
              "4                     0.137   43        1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBO8azPZWfbC"
      },
      "source": [
        "# construct the design matrix for the input features and the outcome vector\n",
        "features = list(train_data.columns.values)\n",
        "features.remove('Outcome')\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['Outcome']\n",
        "X_val = test_data[features]\n",
        "y_val = test_data['Outcome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7VOsiOfZ5cq"
      },
      "source": [
        "### Question 1.1: How many people have outcome \"1\" (diabetes) in the training set? How many people do not have diabetes in the training set? (5 points)\n",
        "Hint: The Pandas library has some handy functions for this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_rb6uaZwgH4"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uSGi7TaakZ-"
      },
      "source": [
        "### Question 1.2: What's the median BMI in the training cohort? What's the median BMI among diabetic and non-diabetic patients in the training and test set, respectively? (5 points)\n",
        "Hint: Feel free to use the Statistics library in Python\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg69NCEXwpvZ"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgdI0qfucJyb"
      },
      "source": [
        "### Question 1.3: Is BMI associated with diabetes in the training cohort? Why? (5 points)\n",
        "Hint: Feel free to use any statistical test, but be sure to **mention the assumption(s) of the test you chose**.\n",
        "\n",
        "Word limit: 100 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsEMvufSwkzQ"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOK9ebs_gPNg"
      },
      "source": [
        "### Question 1.4: From the analyses 1.1-1.3 and the data description (https://www.kaggle.com/uciml/pima-indians-diabetes-database) alone (and without resorting to any of your prior knowledge), do you think losing weight would reduce the training set participants' risk of developing diabetes? (5 points)\n",
        "Word limit: 100 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVRz8u-3wuWR"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOxpyZLoiRFj"
      },
      "source": [
        "## Part 2: Perceptrons and Backpropagation (30 points)\n",
        "In this section, we will implement perceptron and backpropagation from scratch, and apply them to the dataset we explored in Part 1.\n",
        "\n",
        "Please do **NOT** use Keras, Pytorch, Lasagne, Tensorflow, or any other high-level abstraction of machine learning frameworks. Upon completing this exercise from scratch, you will gain a deep understanding of what's under the hood of popular deep learning packages.\n",
        "\n",
        "The only allowed packages are numpy, pandas, and matplotlib.pyplot. The roc_auc_score function in sklearn.metrics is also allowed, but other functions from sklearn are prohibited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0jsQQaLny-N"
      },
      "source": [
        "### Question 2.1: Please complete the function for the forward pass below. (5 points)\n",
        "**No loops are allowed.** Please use only matrix, vector, or element-wise operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKlYvr0O5Tne"
      },
      "source": [
        "# Please complete this function, and make it return the desired result\n",
        "# X: the design matrix of the input features\n",
        "# w: weight vector\n",
        "# return: the output predictions of a perceptron with inputs X and weights w\n",
        "\n",
        "def forward_pass(X,w):\n",
        "    # your code goes here\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkL-X_Ps54aX"
      },
      "source": [
        "### Question 2.2: Please complete the function for the backward pass below. (5 points)\n",
        "**No loops are allowed.** Please use only matrix, vector, or element-wise operations.\n",
        "Hint: Compute and return the average gradient, instead of the sum of gradients.\n",
        "\n",
        "\n",
        "**Use the squared error loss function**: Loss = $\\frac{1}{N}\\sum_{i=1}^N (y_i-p_i)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZYmiA796OaU"
      },
      "source": [
        "# Please complete this function, and make it return the desired result\n",
        "# X: the design matrix of the input features\n",
        "# y: the ground truth of outcome labels (classes)\n",
        "# p: the class probability outputted by the model\n",
        "# return: the average gradient of the perceptron function \n",
        "\n",
        "def backward_pass(y,X,p):\n",
        "    # your code goes here\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8g0Ar1z6q9Q"
      },
      "source": [
        "### Question 2.3: Perceptron (20 points)\n",
        "Train your perceptron using the forward_pass and backward_pass functions for 1,000 epochs. Report the loss, accuracy, area under the receiver operating characteristic curve (AUC) for both the training and validation data sets. Plot the training and validation loss vs. epochs. Modify this cell to include your results and commentary on your approach.\n",
        "\n",
        "Your perceptron should have an AUC > 0.6 when evaluated by the validation data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB_JQ7fgwzXw"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzIzxQ2n7-QV"
      },
      "source": [
        "## Part 3: Perceptrons with L2 regularization (20 points)\n",
        "In this section, we will implement perceptron and backpropagation with L2 regularization from scratch, and apply them to the same dataset from Part 1 again.\n",
        "\n",
        "Train your perceptron with L2 regularization using the forward_pass and backward_pass functions for 1,000 epochs. Report the loss, accuracy, AUC for both the training and validation data sets. Plot the training and validation loss vs. epochs. Modify this cell to include your results and commentary on your approach.\n",
        "\n",
        "Please do **NOT** use Keras, Pytorch, Lasagne, Tensorflow, or any other high-level abstraction machine learning frameworks. Upon completing this exercise from scratch, you will gain a deep understanding of what's under the hood of popular deep learning packages.\n",
        "\n",
        "The only allowed packages are numpy, pandas, and matplotlib.pyplot. The roc_auc_score function in sklearn.metrics is also allowed, but other functions from sklearn are prohibited.\n",
        "\n",
        "**No loops are allowed for the forward/backward pass functions.** Please use only matrix, vector, or element-wise operations.\n",
        "\n",
        "Hint: Think in terms of the forward pass, backward pass, cost function, and training mechanisms. Think how (some of them) would differ from part 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_fOecFKw1XI"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TinhJAU9nIEy"
      },
      "source": [
        "## Part 4: Multi-layer neural network using Keras (30 points)\n",
        "In this section, we will train a multi-layer neural network using the Keras framework, and apply it to the dataset from Part 1. **Use the "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_jAnUefozHY"
      },
      "source": [
        "### Question 4.1 Train a multi-layer neural network using Keras (20 points)\n",
        "Please implement a neural network with at least one hidden layer using Keras, and plot the model accuracy and model loss in both the training and validation sets over the epochs.\n",
        "\n",
        "Your neural network should have an accuracy > 0.7 when evaluated by the validation data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2VgOJM4w5cd"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boQTjaJRXqud"
      },
      "source": [
        "### Question 4.2. Build a logistic regression model using the training set, and evaluate the training and validation set accuracy of the resulting model. (5 points)\n",
        "Feel free to use any pre-built functions for logistic regression.\n",
        "\n",
        "Hint: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZGLUdNqw7kk"
      },
      "source": [
        "# Your codes and answers here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on94uP4Wr2kJ"
      },
      "source": [
        "### Question 4.3. Does your multi-layer neural network perform better than the logistic regression model? Why or why not (name three reasons)? (5 points)\n",
        "Word limit: 200 words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBh6MYoLw9PE"
      },
      "source": [
        "# Your answers here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}